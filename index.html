<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Yiduo Guo (郭一铎)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Yiduo Guo (郭一铎) </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://github.com/gydpku/yiduo.github.io/"><img src="yiduo.jpg" alt="alt text" width="131px" height="160px" /></a>&nbsp;</td>
<td align="left"><p>PH.D. candidate,<br />
Wangxuan Institute,Peking university <br />
Beijing, China <br /> 
E-mail: <a href="2001111363@stu.pku.edu.cn">2001111363@stu.pku.edu.cn</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I am a fourth-year PH.D. candidate at Wangxuan institute, Peking university. I am advised by Prof. <a href="https://www.icst.pku.edu.cn/zhaodongyan/en/">Dongyan Zhao</a> and work closely with Prof. <a href="https://www.cs.uic.edu/~liub/">Bing Liu</a>. I am interested in designing agents that can continually learn new knowledge and enabling foundation models to evolve with time. I was a research intern at Microsoft Research Asia, under the supervision of Duan Nan and Yaobo Liang. Currently, I am a (remote) visiting student at MIT-IBM Lab, under the supervision of Yikang Shen and Jie Fu. </p>
<h2>Research</h2>
<p>My research interests include: </p>
<ul>
<li><p>LLM-based agents that can improve themselves with environmental feedback.</p>
</li>
<li><p>Continual pretraining or finetuning foundation models</p>
</li>
<li><p>Online Class incremental Learning</p>

</li>
</ul>
<h2>Preprint </h2>
<ol>
<li><a href="https://arxiv.org/abs/2304.10464">Learning to Plan with Natural Language</a> Large language models can learn and update natural langauge task plan based on environmental feedback and then use the learned plan to solve reasoning tasks.</p>
</li>
<li><a href="https://arxiv.org/abs/2304.06364">AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models</a> A human-level examination evaluation for artificial general intelligence.</p>
</li>
<li><a href="https://arxiv.org/abs/2311.01767">PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task Completion</a> A multi-turn and multi-modal PPT task compeletion benchmark.</p>
</li>
</ol>
<h2>Recent publications </h2>
<ol>
 <li><p>Yiduo Guo, Yaobo Liang, Liu Bing, Dongyan Zhao,Nan Duan <a href="https://aclanthology.org/2023.acl-long.221.pdf"> Analyzing and Reducing the Performance Gap in Cross-Lingual Transfer
with Fine-tuning Slow and Fast, ACL2023</a> We propose a phrase-related and location-related paramater protection mechanism to reduce cross-lingual knowledege forgetting </p>
  <li><p>Yijia Shao,Yiduo Guo,Dongyan Zhao,Liu Bing <a href="https://aclanthology.org/2023.acl-short.109/"> Class-Incremental Learning based on Label Generation
with Fine-tuning Slow and Fast, ACL2023</a> We find that generation loss is better than cross-entropy loss for class incremental learning in pre-trained language models.</p>
<li><p>Yiduo Guo, Liu Bing, Dongyan Zhao, <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Guo_Dealing_With_Cross-Task_Class_Discrimination_in_Online_Continual_Learning_CVPR_2023_paper.html"> Dealing with Cross-Task Class Discrimination in Online Continual Learning, CVPR2023 </a> We find that establishing cross-task boundaries is a vital problem for class incremental learning </p>
</li>
<li><p>Yiduo Guo, Liu Bing, Dongyan Zhao, <a href="https://proceedings.mlr.press/v162/guo22g.html"> Online Continual Learning through Mutual Information Maximization, ICML2022 </a>a> We find that learning holistic representation is neccessary for class incremental learning and achieve it by mutual information maximization. </p>
</li>
<li><p>Yiduo Guo, Wenpeng Hu, Dongyan Zhao, Liu Bing, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20634"> Adaptive Orthogonal Projection for Batch and Online Continual Learning, AAAI2022 </a>a> We propose an advanced gradient orthogonal algorithm to avoid the forgetting problem.</p>
</li>
</ol>
<p><a href="https://www.semanticscholar.org/author/Yiduo-Guo/2214448244">Full list of publications in Semantic Scholar</a>.</p>
<h2>Academic service</h2>
<p><b>Reviewer for recent two years</b></p>
<ul>
<li><p>Neurips</p>
</li>
<li><p>ICML</p>
</li>
  </li>
<li><p>ICLR</p>
</li>
  </li>  
<li><p>ACL</p>
</li>
<li><p>CVPR</p>
</li>  
<li><p>AAAI</p>
</li>
</ul>
<p><a href="https://scholar.google.com/citations?user=ov-Cb2kAAAAJ">More details in Google Scholar</a></p>
</ol>
<p><br />
</td>
</tr>
</table>
</body>
</html>
